---
title: "p8105_hw5_yw3995"
author: "Yuxuan Wang"
date: "2023-11-11"
output: github_document
---

```{r, message = FALSE}
library(readr)
library(tidyverse)
library(rvest)
library(ggplot2)
```

# Problem 1

```{r, message = FALSE}
raw_data = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

raw_data = read.csv(raw_data)
```

* Raw data describe the homicides in 50 large U.S. cities, which contains **`r ncol(raw_data)`** variables and **`r nrow(raw_data)`** observations.
* Raw data has lots of variables, such as: `r names(raw_data)`, and the key variables are **city, state, disposition**.

```{r, message = FALSE}
tidy_data =
  raw_data |> 
  mutate(city_state = paste(city, state, sep = ", ")) |> 
  group_by(city_state) |> 
  summarise(
    total_homicides = n(), 
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))  
  )

tidy_data = tidy_data[tidy_data$city_state != "Tulsa, AL", ] 

tidy_data
```

```{r, message = FALSE}
baltimore_df = raw_data |> 
  mutate(city_state = paste(city, state, sep = ", ")) |> 
  mutate(disposition = ifelse(disposition == "Closed by arrest", "homicides", "unsolved_homicides")) |> 
  filter(city_state == "Baltimore, MD")

baltimore_result = prop.test(x = sum(baltimore_df$disposition %in% c("unsolved_homicides")), n = nrow(baltimore_df), correct = FALSE)

baltimore_result_tidy = broom::tidy(baltimore_result) |> 
  mutate(confidence_intervals = paste(conf.low, conf.high, sep = ", ")) |> 
  rename(estimated_proportion = estimate) |> 
  select(estimated_proportion, confidence_intervals) 

baltimore_result_tidy
```

```{r, message = FALSE}
city_df = tidy_data |> 
  mutate(
    city_test_result = map2(unsolved_homicides, total_homicides, ~prop.test(x = .x, n = .y)),
    city_tidy_result = map(city_test_result, broom::tidy)
  ) |> 
  select(city_state, city_tidy_result) |> 
  unnest(city_tidy_result) |> 
  select(city_state, estimate, conf.low, conf.high) 


city_tidy_df = city_df |> 
  mutate(confidence_intervals = paste(conf.low, conf.high, sep = ", ")) |> 
  rename(estimated_proportion = estimate) |> 
  select(city_state, estimated_proportion, confidence_intervals)

city_tidy_df
```

```{r, message = FALSE}
ggplot(city_df, aes(x = reorder(city_state, estimate), y = estimate)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2, color = "red") +
  coord_flip() +  
  labs(x = "City",
       y = "Estimated Proportion of Unsolved Homicides",
       title = "Estimates and Confidence Intervals by City") +
  theme_minimal()
```

# Problem 2

```{r, message = FALSE}
file_names = list.files(path = "./data/", full.names = TRUE)

files_df = data.frame(file_path = file_names) |>
  mutate(file_name = basename(file_path),
         arm = sub("_.*", "", file_name), 
         subject_id = sub(".*_", "", sub("\\..*", "", file_name))) 

read_data = function(file_path) {
  read_csv(file_path) |>
    gather(key = "week", value = "observation") 
}

tidy_data_q2 = files_df |>
  mutate(data = map(file_path, read_data)) |> 
  unnest(data) |> 
  mutate(week = as.numeric(gsub("week_", "", week))) |> 
  select(arm, subject_id, week, observation) |> 
  select(subject_id, everything())

tidy_data_q2
```

```{r, message = FALSE}
spaghetti_plot = ggplot(tidy_data_q2, aes(x = week, y = observation, color = subject_id)) +
  geom_point() +
  geom_line() +
  facet_wrap(~arm) +
  labs(
    x = "Week",
    y = "Observation",
    title = "Spaghetti Plot of Observations on Each Subject Over Time",
    color = "subject_id"
  ) +
  theme_minimal()

spaghetti_plot
```
 
* In the `con` (control) group, we observe that weekly observations **consistent fluctuations** within the **range of -1.25 to 3.75**. However, in the `exp` (experimental) group, we can see a **weekly increase** in observations of approximately **3.125**.

# Problem 3

```{r}
set.seed(123)
```

## Generate 5000 datasets from the model

```{r, message = FALSE}
sim_mean_sd = function(n = 30, mu = 0, sigma = 5){
   sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma),
  )
  sim_data |> 
    summarize(
      mu_hat = mean(x),
      sigma_hat = sd(x)
    )
}

output = vector("list", 5000)

for (i in 1:5000) {
  output[[i]] = sim_mean_sd(30)
}

sim_results = bind_rows(output)
```

## Obtain the estimate and p-value when μ=0

```{r, message = FALSE}
sample_means = numeric(5000)
p_values = numeric(5000)

n = 30
sigma = 5
mu = 0

for (i in 1:5000) {
  data = rnorm(n, mean = mu, sd = sigma)
  
  t_test_result = t.test(data)
  result_tidy = broom::tidy(t_test_result)
  
  sample_means[i] = result_tidy$estimate
  p_values[i] = result_tidy$p.value
}

alpha = .05
power = mean(p_values < alpha)

cat("Estimated:", sample_means[i], "\n")
cat("Estimated Power:", power, "\n")
```

## μ={1,2,3,4,5,6}

```{r, message = FALSE}
library(broom)
library(dplyr)

n = 30
sigma = 5
alphas = 0.05  
mu_values = 0:6  

results = data.frame(mu = numeric(), estimate = numeric(), p_value = numeric(), rejected = logical())

for (mu in mu_values) {
  sample_means = numeric(5000)
  p_values = numeric(5000)
  
  for (i in 1:5000) {
    data = rnorm(n, mean = mu, sd = sigma)
    t_test_result = t.test(data, mu = 0)
    result_tidy = tidy(t_test_result)
    sample_means[i] = result_tidy$estimate
    p_values[i] = result_tidy$p.value
  }
 
  rejected = p_values < alphas
  results = rbind(results, data.frame(mu = rep(mu, 5000), estimate = sample_means, p_value = p_values, rejected = rejected)) 
}
```

## A plot showing “Power vs. Effect Size in a One-Sample t-Test”

```{r, message = FALSE}
mean_power = results |> 
  group_by(mu) |> 
  summarize(power = mean(rejected))

ggplot(mean_power, aes(x = mu, y = power)) +
  geom_line() +
  geom_point() +
  labs(x = "True μ (Effect Size)", y = "Power") +
  ggtitle("Power vs. Effect Size in a One-Sample t-Test")
```

* There is a **positive relationship** between effect size and power, which means as Effect Size grows, Power grows. And the Power approaches to 1 gradually.

## A plot showing “Average Estimate of μ^ vs. μ (and Only the Null Was Rejected”

```{r, message = FALSE}
result_rejected = results |> 
  group_by(mu) |> 
  summarise(
    mean_mu_hat = mean(estimate),
    mean_mu_hat_rejected = mean(estimate[rejected])
  )

ggplot(result_rejected, aes(x = mu)) +
  geom_line(aes(y = mean_mu_hat, color = 'pink')) +
  geom_line(aes(y = mean_mu_hat_rejected, color = 'skyblue')) +
  
  geom_point(aes(y = mean_mu_hat, color = 'pink')) +
  geom_point(aes(y = mean_mu_hat_rejected, color = 'skyblue')) +
  
  labs(x = "True μ", y = "Average Estimate of μ^", color = "average estimate of μ^") +
  ggtitle("Average Estimate of μ^ vs. μ (and Only the Null Was Rejected)") +
  scale_color_manual(values = c("pink" = "pink", "skyblue" = "skyblue"), 
                     labels = c("pink" = "average estimate of μ^", "skyblue" = "average estimate of μ^ rejected"))
```

* We find the sample average of μ^ across tests for which the null is rejected **not approximately equal** to the true value of μ when μ = 1, 2, and **approximately equal** when μ = 3, 4, 5, 6. 

* *Not approximately equal*: the effect size is small, and relatively close to the null hypothesis value. This may because the sampling variability and sampling Error, which will causes inherent randomness and the sample average of μ^ across tests for which the null is rejected not approximately equal to the true value of μ.

* *Approximately equal*: the effect size is larger, making it easier to detect a statistically significant difference. This can result in the sample average of μ^ being approximately equal to the true values because the differences are more pronounced and easier to detect.